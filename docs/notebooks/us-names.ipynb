{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe80b124b7d573c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# US baby names dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cef2a4-3270-4f94-b37c-bd8ada31a53c",
   "metadata": {},
   "source": [
    "## Install and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cf8dd-003a-42e3-83df-c19ded1d2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install software\n",
    "# ! pip install --quiet coniferest\n",
    "! pip install --quiet pandas\n",
    "! pip install --quiet requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from coniferest.pineforest import PineForest\n",
    "from coniferest.isoforest import IsolationForest\n",
    "from coniferest.pineforest import PineForest\n",
    "from coniferest.session import Session\n",
    "from coniferest.session.callback import TerminateAfter, prompt_decision_callback, Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85849cf-ae6b-4422-a7b6-39defe4400b6",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010d52e-2e26-494a-90e2-d8c552f39dd9",
   "metadata": {},
   "source": [
    "Download data and put into a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14ad6e-838b-4ea7-a97b-b90c2478b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "URL = 'https://www.ssa.gov/OACT/babynames/state/namesbystate.zip'\n",
    "\n",
    "response = requests.get(URL)\n",
    "if not response.ok:\n",
    "    raise RuntimeError('Cannot download the file')\n",
    "\n",
    "dfs = []\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "    for filename in zip_ref.namelist():\n",
    "        if not filename.lower().endswith('.txt'):\n",
    "            continue\n",
    "        with zip_ref.open(filename) as f:\n",
    "            df = pd.read_csv(f, header=None, names=['State', 'Gender', 'Year', 'Name', 'Count'])\n",
    "        dfs.append(df)\n",
    "raw = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb0285-36bc-4b12-be08-37e456f147a6",
   "metadata": {},
   "source": [
    "Let's load the data and transform it into a feature matrix where each column is the number (normalized) of americans that got this name in a given year (from 1910 to 2014). We apply few quality filter. We should at least have data in 10 years, otherwise we consider it too much missing data and drop the name. We also require the name to appear at least 10000 times over the full time range, this will prevent noisy data from names that are barely used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e9a5c-fa19-4802-b83b-a9cca5b481ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "WITH_FFT = True\n",
    "\n",
    "all_years = np.unique(raw['Year'])\n",
    "all_names = np.unique(raw['Name'])\n",
    "\n",
    "# Accumulate names over states and genders\n",
    "counts = raw.groupby(['Name', 'Year']).apply(lambda df: df['Count'].sum(), include_groups=False)\n",
    "\n",
    "# Tranform to dataframe where names are labels, years are columns and counts are values (features)\n",
    "years = [f'year_{i}' for i in all_years]\n",
    "year_columns = pd.DataFrame(data=0.0, index=all_names, columns=years)\n",
    "for name, year in counts.index:\n",
    "    year_columns.loc[name, f'year_{year}'] = counts.loc[name, year]\n",
    "\n",
    "# Account for total population changes\n",
    "trend = year_columns.sum(axis=0)\n",
    "detrended = year_columns / trend\n",
    "\n",
    "# Normalise and filter\n",
    "norm = detrended.apply(lambda column: column / detrended.max(axis=1))\n",
    "filtered = norm[year_columns.sum(axis=1) >= 10_000]\n",
    "\n",
    "if WITH_FFT:\n",
    "    # Fourier-transform, normalize by zero frequency and get power-spectrum for few lowest frequencies\n",
    "    power_spectrum = np.square(np.abs(np.fft.fft(filtered)))\n",
    "    power_spectrum_norm = power_spectrum / power_spectrum[:, 0, None]\n",
    "    power_spectrum_low_freq = power_spectrum_norm[:, 1:21]\n",
    "    frequencies = [f'freq_{i}' for i in range(power_spectrum_low_freq.shape[1])]\n",
    "    power = pd.DataFrame(data=power_spectrum_low_freq, index=filtered.index, columns=frequencies)\n",
    "    \n",
    "    # Concatenate time-series data and power spectrum\n",
    "    final = pd.merge(filtered, power, left_index=True, right_index=True)\n",
    "else:\n",
    "    # Use time-series data\n",
    "    final = filtered\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696e452-966e-4209-97b1-d6d6684ba542",
   "metadata": {},
   "source": [
    "Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403af70-6116-4523-9036-0467a142a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_plot(idx):\n",
    "    cols = [col.startswith('year') for col in final.columns]\n",
    "    all_years = [int(col.removeprefix('year_')) for col in final.columns[cols]]\n",
    "    \n",
    "    if isinstance(idx, str):\n",
    "        counts = final.loc[idx][cols]\n",
    "        title = idx\n",
    "    else:\n",
    "        counts = final.iloc[idx][cols]\n",
    "        title = final.iloc[idx].name\n",
    "    \n",
    "    plt.plot(all_years, counts.values)\n",
    "    # plt.ylim(-0.1, 1.1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac11144-8fd8-4044-b4bf-07ce105322ef",
   "metadata": {},
   "source": [
    "We can now easily look at the evolution of a given name over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final))\n",
    "basic_plot('Anastasia')\n",
    "basic_plot('Leo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4799cd6-f209-48b4-9d7e-f171362c5c8c",
   "metadata": {},
   "source": [
    "## Classical anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25516e-d8da-4612-b716-87f143fead52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IsolationForest(random_seed=1, n_trees=1000)\n",
    "model.fit(np.array(final))\n",
    "scores = model.score_samples(np.array(final))\n",
    "ordered_scores, ordered_index = zip(*sorted(zip(scores, final.index)))\n",
    "\n",
    "print(f\"Top 10 weirdest names : {ordered_index[:10]}\")\n",
    "print(f\"Top 10 most normal names : {ordered_index[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce10ca9-c592-42b4-973b-f7f0a8bf3815",
   "metadata": {},
   "source": [
    "Let's have a look at their distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea04e3-e446-4854-9b8c-f1c231536e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for normal in ordered_index[-4:]:\n",
    "    basic_plot(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cceb0df-4f07-4fb0-b5cc-e86e29053fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weird in ordered_index[:4]:\n",
    "    basic_plot(weird)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb8939-ceca-469c-8ead-79ba3877e7d5",
   "metadata": {},
   "source": [
    "It seems that anomalies are either very localised peak or very recent trending names. Notice how Olive is a tricky one because it is both a localised peak and a recent trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c696fd1-98da-419d-bbe8-51f377cb2ac2",
   "metadata": {},
   "source": [
    "## Active Anomaly Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653700d8-6199-476a-b260-7158fe3f034f",
   "metadata": {},
   "source": [
    "First, we need a function helping us to make a decision.\n",
    "\n",
    "### Comment dummy decision function and uncomment interactive one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8195d-8b4e-44e3-b73f-0d446a50a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment\n",
    "def help_decision(metadata, data, session):\n",
    "    \"\"\"Dummy, says YES to everything\"\"\"\n",
    "    return Label.ANOMALY\n",
    "\n",
    "### UNCOMMENT\n",
    "# def help_decision(metadata, data, session):\n",
    "#     \"\"\"Plots data and asks expert interactively\"\"\"\n",
    "#     basic_plot(metadata)\n",
    "#     return prompt_decision_callback(metadata, data, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d4c2d-8545-447c-a7b4-b9fa5f1a173f",
   "metadata": {},
   "source": [
    "Let's create a model and run a session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a3d594-a818-4db4-ad0c-383111fb04c9",
   "metadata": {},
   "source": [
    "Let's run PineForest and say YES every time we see a recent growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6861278-7822-4a86-910c-4772de2c1487",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PineForest(\n",
    "    # Number of trees to use for predictions\n",
    "    n_trees=256,\n",
    "    # Number of new tree to grow for each decision\n",
    "    n_spare_trees=768,\n",
    "    # Fix random seed for reproducibility\n",
    "    random_seed=0,\n",
    ")\n",
    "session = Session(\n",
    "    data=final,\n",
    "    metadata=final.index,\n",
    "    model=model,\n",
    "    decision_callback=help_decision,\n",
    "    on_decision_callbacks=[\n",
    "        TerminateAfter(10),\n",
    "    ],\n",
    ")\n",
    "session.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e245ee2-08e6-4304-ae86-f65860280c63",
   "metadata": {},
   "source": [
    "Wow ! Good almost 100% of the behavior we were looking for\n",
    "\n",
    "Now we can run it again and say YES every time we see a sharp peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0746e-594d-4333-95ef-6404050f277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PineForest(\n",
    "    # Number of trees to use for predictions\n",
    "    n_trees=256,\n",
    "    # Number of new tree to grow for each decision\n",
    "    n_spare_trees=768,\n",
    "    # Fix random seed for reproducibility\n",
    "    random_seed=0,\n",
    ")\n",
    "session = Session(\n",
    "    data=final,\n",
    "    metadata=final.index,\n",
    "    model=model,\n",
    "    decision_callback=help_decision,\n",
    "    on_decision_callbacks=[\n",
    "        TerminateAfter(20),\n",
    "    ],\n",
    ")\n",
    "session.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed8132-fa11-4b64-8caa-f6c3656c56d0",
   "metadata": {},
   "source": [
    "Again, very quickly PineForest learns the profile interesting for the user and outputs it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
